{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 분류 모델 97% 이상 달성\n",
    "\n",
    "# Trainer 클래스와 콜백을 활용하여, MNIST 손글씨 숫자 데이터셋을 분류하는 MLP 모델 구축.\n",
    "# 1. torchvision.dataset.MINIST를 활용하여 데이터셋과 데이터로더를 준비. ok\n",
    "# 2. Trainer 객체 생성. ok\n",
    "#    CheckpointCallback, EarlyStoppingCallback, LoggingCallback 사용\n",
    "#    CheckpointCallback : 모델 체크포인트 저장 ok\n",
    "#    EarlyStoppingCallback : 검증 손실이 일정 epoch 동안 향상되지 않으면 학습 조기 종료 ok\n",
    "#    LoggingCallback : 학습 로그 출력 (epoch, loss) ok\n",
    "# 3. 분류 97% 이상 달성. (lr, parmateter 조정) ok\n",
    "# 4. 모든 랜덤 시드 (random, numpy, torch)를 고정했을 때, 항상 동일한 결과가 나와야 함. (재현성) ok\n",
    "#    테스트 정확도 +-0.2%\n",
    "# 5. 실행 후, 학습 로그가 정상적으로 출력되고 가장 좋은 성능의 모델의 체크포인프 파일(.pth)가 실제로 생성되어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뭔 보안 인증 문제로 인증 검증을 비활성화 하는 코드가 필요하다고 함.\n",
    "import ssl\n",
    "import time, os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from typing import Tuple, List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# MNIST 데이터셋 준비\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# SSL 인증서 검증 비활성화\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 기본 구조 정의\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    model = None\n",
    "    epochs : int = 30\n",
    "    seed: int = 42\n",
    "    learning_rate : float = 1e-4\n",
    "    batch_size = 64\n",
    "    hidden_layers : List[int] = field(default_factory = lambda : [128, 64])\n",
    "    use_mixed_precision: bool = True\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.learning_rate <= 0:\n",
    "            raise ValueError(\"Learning rate must be positive.\")\n",
    "        if self.epochs <= 0:\n",
    "            raise ValueError(\"Number of epochs must be positive.\")\n",
    "        if self.batch_size <= 0:\n",
    "            raise ValueError(\"Batch size must be positive.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.\n",
    "# Callback을 활용하여 Trainer 객체를 정의.\n",
    "# Callback 기본 구조 정의\n",
    "class BaseCallback:\n",
    "    def on_train_begin(self, trainer): pass\n",
    "    def on_epoch_begin(self, trainer): pass\n",
    "    def on_batch_end(self, trainer): pass\n",
    "    def on_epoch_end(self, trainer): pass\n",
    "    def on_train_end(self, trainer): pass\n",
    "    def checkpoint(self, trainer): pass # on_epoch_end 시점에 이전보다 성능이 좋으면 .pth 파일로 모델 저장.\n",
    "    def earlystoppint(self, trainer): pass # 일정 횟수 이상 성능 향상이 없으면 학습 조기 종료."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단 MLP 구축\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_layer, h_layer, out_num) :\n",
    "        super().__init__()\n",
    "        self.flatten_size = in_layer * in_layer\n",
    "        self.in_layer = nn.Linear(self.flatten_size, h_layer[0])\n",
    "        self.h_layer = nn.Linear(h_layer[0], h_layer[1])\n",
    "        self.out_layer = nn.Linear(h_layer[1], out_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # vector화\n",
    "        x = x.view(-1, self.flatten_size)\n",
    "        # 순전파\n",
    "        x = F.relu(self.in_layer(x))\n",
    "        x = F.relu(self.h_layer(x))\n",
    "        return self.out_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 클래스 정의\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, test_loader, optimizer, loss_fn, \n",
    "                 # optim.lr_scheduler._LRScheduler -> learning rate 스케줄러. 학습 도중에 학습률을 동적으로 조정하는 데 사용됨.\n",
    "                 scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
    "                 callbacks: Optional[List[BaseCallback]] = None,\n",
    "                 device: str = \"cuda\"):\n",
    "        \n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        # self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.scheduler = scheduler\n",
    "        self.callbacks = callbacks if callbacks else []\n",
    "        self.device = device\n",
    "        # state 변수에는 학습의 상태를 지속적으로 업데이트 함.\n",
    "        self.state = {}\n",
    "\n",
    "    # 콜백 메서드를 실행하는 함수\n",
    "    def _run_callbacks(self, event_name : str):\n",
    "        for callback in self.callbacks:\n",
    "            # print(f\"callback {event_name}\")\n",
    "            # getattr 함수 : 객체의 속성, 메서드를 동적으로 가져올 때 사용함.\n",
    "            # 여기에서는 콜백의 각 이벤트 메서드를 호출하는 용도로 사용됨.\n",
    "            # 즉, 콜백에서만 사용되는 함수는 아님.\n",
    "            getattr(callback, event_name)(self)\n",
    "\n",
    "    # 학습을 수행하는 파트\n",
    "    def fit(self, num_epochs: int, config : TrainingConfig):\n",
    "        self._run_callbacks(\"on_train_begin\") # 학습 시작 시점에 콜백 불러서 state 초기화\n",
    "        self.state['config'] = config\n",
    "        # 모델 학습 시작\n",
    "        for i in range(num_epochs):\n",
    "            self.state[\"epoch\"] = i + 1\n",
    "            self._run_callbacks(\"on_epoch_begin\")\n",
    "\n",
    "            # 학습/검증 루프 \n",
    "            for idx, data in enumerate(self.train_loader) :  # 배치 학습 루프\n",
    "                input, output = data\n",
    "                # TODO: 모델 삽입\n",
    "                # 순전파\n",
    "                x = self.model(input)\n",
    "                loss = self.loss_fn(x, output)\n",
    "\n",
    "                # 역전파\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                r_loss = self.state.get(\"running_loss\")\n",
    "                self.state['cur_loss'] = loss.item()\n",
    "                if r_loss is None:\n",
    "                    self.state[\"running_loss\"] = loss.item()\n",
    "                else : \n",
    "                    self.state[\"running_loss\"] += loss.item()\n",
    "                    \n",
    "                # self._run_callbacks(\"on_batch_end\")\n",
    "\n",
    "            self._run_callbacks(\"on_epoch_end\")\n",
    "            \n",
    "            # 지난 loss 와 현재 loss의 차이가 별로 없을 경우, no improve +1\n",
    "            loss_dif = abs(self.state.get('cur_loss') - self.state.get('prev_loss'))\n",
    "            # print(loss_dif)\n",
    "            if loss_dif <= 1e-4:\n",
    "                print(\"no improve loss\")\n",
    "                self.state['no_improve_epochs'] += 1\n",
    "            self.state['prev_loss'] = self.state.get('cur_loss')\n",
    "\n",
    "            self.test()\n",
    "\n",
    "            self._run_callbacks(\"earlystoppint\")\n",
    "            \n",
    "        self.state['cur_model_state'] = None # TODO: 현재 모델의 상태 저장\n",
    "        self._run_callbacks(\"checkpoint\") # 매 epoch 마다 체크포인트 저장\n",
    "        self._run_callbacks(\"on_train_end\")\n",
    "\n",
    "    # 테스트를 하는 함수\n",
    "    def test(self):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(self.test_loader):\n",
    "                input, output = data\n",
    "                result = self.model(input)\n",
    "                # 각 예측값 중, 가장 높은 것을 답으로 선택\n",
    "                _, pred = torch.max(result.data, 1) \n",
    "                total += output.size(0)\n",
    "                correct += (pred == output).sum().item() # 맞춘 갯수만큼 더해줌\n",
    "                \n",
    "        acc = 100 * correct / total\n",
    "\n",
    "        abs_acc = abs(self.state.get('cur_acc') - acc)\n",
    "        print(f\"[debug] {abs_acc}\")\n",
    "        if  abs_acc <= 1e-5:\n",
    "            print(\"[debug] no_improve_epochs + 1\")\n",
    "            imp = self.state.get('no_improve_epochs')\n",
    "            self.state['no_improve_epochs'] = int(imp) + 1\n",
    "\n",
    "        if self.state.get('best_acc') < self.state.get('cur_acc') :\n",
    "            self.state['no_improve_epochs'] = 0 # acc 가 오르면 no improve 초기화\n",
    "            print(\"[debug] cur acc > best acc\")\n",
    "            self.state['best_acc'] = acc\n",
    "            self.state['cur_acc'] = acc\n",
    "        else:\n",
    "            self.state['cur_acc'] = acc\n",
    "        \n",
    "        print(f\"accuracy : {acc:.4f}%\")\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingCallBack(BaseCallback):        \n",
    "    def on_train_begin(self, trainer : Trainer) :\n",
    "        # print(\"=== Training started ===\")\n",
    "        trainer.state['config'] = None\n",
    "        trainer.state['epoch'] = 0 # epoch를 담을 state\n",
    "        trainer.state['epoch_start_time'] = 0\n",
    "        trainer.state['epoch_end_time'] = 0\n",
    "        trainer.state['batch'] = 0 # batch 순번을 담을 state\n",
    "        trainer.state['stop'] = False # 학습 종료 여부\n",
    "        trainer.state['running_loss'] = None # running중의 loss를 기록\n",
    "        trainer.state['cur_loss'] = 0 # 현재 loss\n",
    "        trainer.state['prev_loss'] = 0 # 저번 loss\n",
    "        trainer.state['best_acc'] = 0 # 가장 좋은 성능의 acc\n",
    "        trainer.state['cur_acc'] = 0 # 현재 성능의 acc\n",
    "        trainer.state['best_metric'] = None # 가장 좋은 성능을 기록\n",
    "        trainer.state['cur_model_state'] = None # 현재 모델의 파라미터\n",
    "        trainer.state['best_model_state'] = None # 가장 성능 좋은 모델의 파라미터\n",
    "        trainer.state['no_improve_epochs'] = 0 # 성능 향상이 없는 epoch 수\n",
    "\n",
    "    def on_epoch_begin(self, trainer) : \n",
    "        # print(f\"=== Epoch {trainer.state.get('epoch')} started ===\")\n",
    "        trainer.state['epoch_start_time'] = time.time()\n",
    "\n",
    "    def on_batch_end(self, trainer) : \n",
    "        print(f\"=== Batch {trainer.state.get('batch')} processed ===\")\n",
    "\n",
    "    def on_epoch_end(self, trainer): \n",
    "        trainer.state['epoch_end_time'] = time.time()\n",
    "        epoch = trainer.state.get('epoch')\n",
    "        epochs = trainer.state.get('config').epochs\n",
    "        loss = trainer.state.get('cur_loss')\n",
    "        spend_time = trainer.state.get('epoch_end_time') - trainer.state.get('epoch_start_time')\n",
    "        print(f\"=== Epoch {epoch}/{epochs} | loss {loss:.4f} | epoch time {spend_time:.4f} s ===\")\n",
    "\n",
    "    def on_train_end(self, trainer):\n",
    "        if trainer.state.get('stop') == True :\n",
    "            print(\"=== Training ended ===\")\n",
    "\n",
    "    # on_epoch_end 시점에 이전보다 성능이 좋으면 .pth 파일로 모델 저장.\n",
    "    def checkpoint(self, trainer) : \n",
    "        cur_model_state = trainer.state.get('cur_model_state')\n",
    "        prev_model_state = trainer.state.get('best_model_state')\n",
    "        conf = trainer.state.get('config')\n",
    "\n",
    "        daytime = time.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "        column = [\"code\", \"model\", \"epoch\", \"seed\", \"learning_rate\", \"batch_size\", \"hidden_layers\", \"use_mixed_precision\"]\n",
    "        value = [[f\"{daytime}\", conf.model, conf.epochs, conf.seed, conf.learning_rate, conf.batch_size, conf.hidden_layers, conf.use_mixed_precision]]\n",
    "        df = pd.DataFrame(value, columns = column)\n",
    "\n",
    "        if prev_model_state is None or cur_model_state['accuracy'] > prev_model_state['accuracy'] :\n",
    "            trainer.state['best_model_state'] = cur_model_state # 가장 성능 좋은 모델의 파라미터를 교체\n",
    "            print(\"New best model found, saving checkpoint...\")\n",
    "            \n",
    "            torch.save(cur_model_state, f\"best_model_{daytime}.pht\")\n",
    "\n",
    "            if not os.path.exists(\"config.csv\"):\n",
    "                df.to_csv(\"config.csv\", index = False)\n",
    "            else:\n",
    "                df_config = pd.read_csv(\"config.csv\")\n",
    "                df_config = pd.concat([df_config, df], ignore_index = True)\n",
    "                df_config.to_csv(\"config.csv\", index = False)\n",
    "\n",
    "    def earlystoppint(self, trainer): # 일정 횟수 이상 성능 향상이 없으면 학습 조기 종료.\n",
    "        if trainer.state.get('no_improve_epochs') >= 3 :\n",
    "            print(\"Early stopping triggered.\")\n",
    "            trainer.state['stop'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1/30 | loss 0.2361 | epoch time 4.0339 s ===\n",
      "[debug] 91.99\n",
      "accuracy : 91.9900%\n",
      "=== Epoch 2/30 | loss 0.1948 | epoch time 3.9429 s ===\n",
      "[debug] 2.410000000000011\n",
      "[debug] cur acc > best acc\n",
      "accuracy : 94.4000%\n",
      "=== Epoch 3/30 | loss 0.2759 | epoch time 3.8907 s ===\n",
      "[debug] 1.3000000000000114\n",
      "accuracy : 93.1000%\n",
      "=== Epoch 4/30 | loss 0.1522 | epoch time 3.8248 s ===\n",
      "[debug] 1.7800000000000011\n",
      "accuracy : 94.8800%\n",
      "=== Epoch 5/30 | loss 0.0307 | epoch time 4.2618 s ===\n",
      "[debug] 0.20000000000000284\n",
      "[debug] cur acc > best acc\n",
      "accuracy : 95.0800%\n",
      "=== Epoch 6/30 | loss 0.1891 | epoch time 4.0600 s ===\n",
      "[debug] 1.289999999999992\n",
      "accuracy : 93.7900%\n",
      "=== Epoch 7/30 | loss 0.0164 | epoch time 4.7943 s ===\n",
      "[debug] 0.8399999999999892\n",
      "accuracy : 94.6300%\n",
      "=== Epoch 8/30 | loss 0.1068 | epoch time 4.5302 s ===\n",
      "[debug] 0.6899999999999977\n",
      "accuracy : 93.9400%\n",
      "=== Epoch 9/30 | loss 0.2247 | epoch time 4.1515 s ===\n",
      "[debug] 1.0600000000000023\n",
      "accuracy : 95.0000%\n",
      "=== Epoch 10/30 | loss 0.4303 | epoch time 3.8670 s ===\n",
      "[debug] 0.09999999999999432\n",
      "accuracy : 95.1000%\n",
      "=== Epoch 11/30 | loss 0.0228 | epoch time 3.8225 s ===\n",
      "[debug] 0.28000000000000114\n",
      "[debug] cur acc > best acc\n",
      "accuracy : 95.3800%\n",
      "=== Epoch 12/30 | loss 0.0207 | epoch time 3.7987 s ===\n",
      "[debug] 0.3299999999999983\n",
      "accuracy : 95.0500%\n",
      "=== Epoch 13/30 | loss 0.1072 | epoch time 3.9335 s ===\n",
      "[debug] 0.269999999999996\n",
      "accuracy : 95.3200%\n",
      "=== Epoch 14/30 | loss 0.1638 | epoch time 3.8083 s ===\n",
      "[debug] 0.0\n",
      "[debug] no_improve_epochs + 1\n",
      "accuracy : 95.3200%\n",
      "=== Epoch 15/30 | loss 0.0864 | epoch time 3.8041 s ===\n",
      "[debug] 0.8799999999999955\n",
      "accuracy : 94.4400%\n",
      "=== Epoch 16/30 | loss 0.1978 | epoch time 3.8333 s ===\n",
      "[debug] 0.8400000000000034\n",
      "accuracy : 95.2800%\n",
      "=== Epoch 17/30 | loss 0.0784 | epoch time 3.7917 s ===\n",
      "[debug] 0.0\n",
      "[debug] no_improve_epochs + 1\n",
      "accuracy : 95.2800%\n",
      "=== Epoch 18/30 | loss 0.1135 | epoch time 3.8927 s ===\n",
      "[debug] 0.01999999999999602\n",
      "accuracy : 95.3000%\n",
      "=== Epoch 19/30 | loss 0.0864 | epoch time 3.8320 s ===\n",
      "[debug] 0.009999999999990905\n",
      "accuracy : 95.2900%\n",
      "=== Epoch 20/30 | loss 0.1443 | epoch time 3.7951 s ===\n",
      "[debug] 0.8300000000000125\n",
      "accuracy : 94.4600%\n",
      "=== Epoch 21/30 | loss 0.0571 | epoch time 3.7852 s ===\n",
      "[debug] 0.5500000000000114\n",
      "accuracy : 95.0100%\n",
      "=== Epoch 22/30 | loss 0.1997 | epoch time 3.9468 s ===\n",
      "[debug] 0.3499999999999943\n",
      "accuracy : 95.3600%\n",
      "=== Epoch 23/30 | loss 0.2267 | epoch time 4.0125 s ===\n",
      "[debug] 0.21999999999999886\n",
      "accuracy : 95.5800%\n",
      "=== Epoch 24/30 | loss 0.3011 | epoch time 3.9131 s ===\n",
      "[debug] 0.0799999999999983\n",
      "[debug] cur acc > best acc\n",
      "accuracy : 95.6600%\n",
      "=== Epoch 25/30 | loss 0.1354 | epoch time 3.8898 s ===\n",
      "[debug] 5.239999999999995\n",
      "accuracy : 90.4200%\n",
      "=== Epoch 26/30 | loss 0.0323 | epoch time 3.9245 s ===\n",
      "[debug] 5.079999999999998\n",
      "accuracy : 95.5000%\n",
      "=== Epoch 27/30 | loss 0.0613 | epoch time 4.7413 s ===\n",
      "[debug] 0.10999999999999943\n",
      "accuracy : 95.3900%\n",
      "=== Epoch 28/30 | loss 0.5694 | epoch time 4.1121 s ===\n",
      "[debug] 0.37999999999999545\n",
      "accuracy : 95.0100%\n",
      "=== Epoch 29/30 | loss 0.0232 | epoch time 4.0910 s ===\n",
      "[debug] 0.9299999999999926\n",
      "accuracy : 95.9400%\n",
      "=== Epoch 30/30 | loss 0.0353 | epoch time 4.1439 s ===\n",
      "[debug] 0.4299999999999926\n",
      "[debug] cur acc > best acc\n",
      "accuracy : 95.5100%\n",
      "New best model found, saving checkpoint...\n"
     ]
    }
   ],
   "source": [
    "m_conf = TrainingConfig()\n",
    "m_conf.learning_rate = 1e-2\n",
    "callback = LoggingCallBack()\n",
    "\n",
    "torch.manual_seed(m_conf.seed) # seed 고정해서 dataloader의 random shuffle을 고정시킴\n",
    "\n",
    "# normalized 된 MNIST 데이터셋을 Tensor 형태로 변환하여 불러옴.\n",
    "# print(\"=== Load Train Data ===\")\n",
    "train_data = datasets.MNIST('./train_data', train = True, download = True,\n",
    "                      transform = transforms.Compose([\n",
    "                          transforms.ToTensor(), \n",
    "                          transforms.Normalize(mean = (0.5,), std = (0.5,))]))\n",
    "# print(\"=== Load Test Data ===\")\n",
    "test_data = datasets.MNIST('./test_data', train = False, download = True,\n",
    "                      transform = transforms.Compose([\n",
    "                          transforms.ToTensor(), \n",
    "                          transforms.Normalize(mean = (0.5,), std = (0.5,))]))\n",
    "\n",
    "# 데이터 로더에 데이터셋을 담아서 정의\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = m_conf.batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = m_conf.batch_size, shuffle = True)\n",
    "\n",
    "model = MLP(28, m_conf.hidden_layers, m_conf.epochs)\n",
    "optim = torch.optim.Adam(model.parameters(), m_conf.learning_rate)\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, train_loader, test_loader, optim, loss_f, None, [callback])\n",
    "trainer.fit(m_conf.epochs, m_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
