{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 길이: 100\n",
      "첫 번째 데이터: torch.Size([28, 28]), 3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "\n",
    "# typing 활용\n",
    "# torch의 Dataset을 상속받아서 데이터셋 클래스 정의\n",
    "# Dataset 은 구조체의 역할 정도만 기대하므로, 복잡한 기능은 넣지 않음\n",
    "# 즉, 전처리 등의 기능은 넣을 필요가 없음. dataloader의 역할.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, targets:torch.Tensor):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, int]:\n",
    "        #idx 에 해당하는 데이터와 레이블을 반환\n",
    "        return self.data[idx], self.targets[idx]\n",
    "    \n",
    "# 예시\n",
    "dummy_data = torch.randn(100, 28, 28) # 100개의 28x28 이미지\n",
    "dummy_targets = torch.randint(0, 10, (100,))\n",
    "my_dataset = CustomDataset(dummy_data, dummy_targets)\n",
    "print(f\"데이터셋 길이: {len(my_dataset)}\")\n",
    "print(f\"첫 번째 데이터: {my_dataset[0][0].shape}, {my_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배치 이미지 크기 : torch.Size([16, 28, 28])\n",
      "배치 레이블 크기 : torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader 는 Dataset 을 감싸서 사용함.\n",
    "data_loader = DataLoader(\n",
    "    dataset = my_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True,\n",
    "    # num_workers = 2 # 워커가 안 됨 (윈도우 이슈\n",
    ")\n",
    "\n",
    "# for 루프를 통해 미니배치를 하나씩 꺼내 쓸 수 있음.\n",
    "for images, labels in data_loader:\n",
    "    print(f\"배치 이미지 크기 : {images.shape}\")\n",
    "    print(f\"배치 레이블 크기 : {labels.shape}\")\n",
    "    break # 첫 배치만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonayeon/git/devops_hs/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m scaler = torch.amp.GradScaler()\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m.zero_grad()\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(): \u001b[38;5;66;03m# 해당 블록 안에서 AMP가 적용됨\u001b[39;00m\n\u001b[32m      8\u001b[39m         outputs = torch.model(images)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/devops_hs/.venv/lib/python3.11/site-packages/torch/__init__.py:2745\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _lazy_modules:\n\u001b[32m   2743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2745\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'optimizer'"
     ]
    }
   ],
   "source": [
    "# 학습 루프 내 사용 예시\n",
    "optimizer = torch.optim.Adam(params=[], lr = 1e-3)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "for images, labels in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.amp.autocast() : # 해당 블록 안에서 AMP가 적용됨\n",
    "        # 학습 부분에서만 amp.autocase(32비트를 16비트로 쪼개서 계산)를 사용하겠다!\n",
    "        # 연산 최적화\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "    # loss 를 스케일링하고 backward()호출\n",
    "    # 스케일링을 하는 이유 : 작은 값이 소실되는 것을 방지하기 위함.\n",
    "    scaler.scale(loss).backward()\n",
    "    # 파라미터 업데이트 (unscale 자동 수행)\n",
    "    # 중요한 점은 optimiser 를 최적화 한 뒤에 스케일러를 업데이트 한다는 것.\n",
    "    scaler.step(optimizer) \n",
    "    # 다음 반복을 위해 스케일러 업데이트\n",
    "    scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 클래스와 콜백을 활용하여, MNIST 손글씨 숫자 데이터셋을 분류하는 MLP 모델 구축.\n",
    "# 1. torchvision.dataset.MINIST를 활용하여 데이터셋과 데이터로더를 준비.\n",
    "# 2. Trainer 객체 생성.\n",
    "#    CheckpointCallback, EarlyStoppingCallback, LoggingCallback 사용\n",
    "#    CheckpointCallback : 모델 체크포인트 저장\n",
    "#    EarlyStoppingCallback : 검증 손실이 일정 epoch 동안 향상되지 않으면 학습 조기 종료\n",
    "#    LoggingCallback : 학습 로그 출력 (epoch, loss)\n",
    "# 3. 분류 97% 이상 달성. (lr, parmateter 조정)\n",
    "# 4. 모든 랜덤 시드 (random, numpy, torch)를 고정했을 때, 항상 동일한 결과가 나와야 함. (재현성)\n",
    "#    테스트 정확도 +-0.2%\n",
    "# 5. 실행 후, 학습 로그가 정상적으로 출력되고 가장 좋은 성능의 모델의 체크포인프 파일(.pth)가 실제로 생성되어야 함.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
